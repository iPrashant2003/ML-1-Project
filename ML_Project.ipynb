{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6buWWHZ2wCi9",
        "outputId": "1f8771d9-003c-409b-b047-d282e38d4f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression trained successfully.\n",
            "Random Forest trained successfully.\n",
            "Gradient Boosting trained successfully.\n",
            "\n",
            "Linear Regression Evaluation Metrics:\n",
            "  MAE  : 0.158\n",
            "  RMSE : 0.200\n",
            "  R²   : -0.531\n",
            "  MAPE : 73.156%\n",
            "\n",
            "Random Forest Evaluation Metrics:\n",
            "  MAE  : 0.119\n",
            "  RMSE : 0.160\n",
            "  R²   : 0.023\n",
            "  MAPE : 53.888%\n",
            "\n",
            "Gradient Boosting Evaluation Metrics:\n",
            "  MAE  : 0.118\n",
            "  RMSE : 0.158\n",
            "  R²   : 0.039\n",
            "  MAPE : 55.945%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Data Loading\n",
        "df = pd.read_csv('/content/Dataset.csv')\n",
        "\n",
        "# 2. Data Cleaning and Preprocessing\n",
        "# a. Handle Missing Values\n",
        "df['All Bed Occupancy Rate'] = df['All Bed Occupancy Rate'].fillna(df['All Bed Occupancy Rate'].median())\n",
        "if 'ICU Bed Source Last Updated' in df.columns:\n",
        "    df = df.drop('ICU Bed Source Last Updated', axis=1)\n",
        "\n",
        "# Fill missing numerical values\n",
        "numerical_cols_with_missing_values = [\n",
        "    'Staffed All Beds', 'Staffed ICU Beds', 'Licensed All Beds',\n",
        "    'ICU Bed Occupancy Rate', 'Population', 'Population (20+)', 'Population (65+)'\n",
        "]\n",
        "for col in numerical_cols_with_missing_values:\n",
        "    if col in df.columns and df[col].isnull().any():\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Fill missing categorical values\n",
        "categorical_cols_with_missing_values = ['ICU Bed Source']\n",
        "for col in categorical_cols_with_missing_values:\n",
        "    if col in df.columns and df[col].isnull().any():\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# b. Handle Outliers using IQR method\n",
        "numerical_cols_for_outlier_handling = [\n",
        "    'Staffed All Beds', 'Staffed ICU Beds', 'Licensed All Beds',\n",
        "    'All Bed Occupancy Rate', 'ICU Bed Occupancy Rate',\n",
        "    'Population', 'Population (20+)', 'Population (65+)'\n",
        "]\n",
        "for col in numerical_cols_for_outlier_handling:\n",
        "    if col in df.columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
        "\n",
        "# 3. Feature Engineering\n",
        "df['Staffed_Beds_Population'] = df['Staffed All Beds'] * df['Population']\n",
        "df['Licensed_Beds_Population'] = df['Licensed All Beds'] * df['Population']\n",
        "df['Staffed_Beds_Squared'] = df['Staffed All Beds']**2\n",
        "df['Population_Squared'] = df['Population']**2\n",
        "\n",
        "# Encode Categorical Features\n",
        "cat_cols = ['State', 'County Name', 'ICU Bed Source']\n",
        "cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "encoded_features = encoder.fit_transform(df[cat_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n",
        "\n",
        "df = pd.concat([df.drop(cat_cols, axis=1), encoded_df], axis=1)\n",
        "\n",
        "# 4. Data Splitting\n",
        "target_col = 'All Bed Occupancy Rate'\n",
        "X = df.drop(target_col, axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# 5. Scale Numerical Features\n",
        "numerical_cols = [\n",
        "    'Staffed All Beds', 'Staffed ICU Beds', 'Licensed All Beds',\n",
        "    'ICU Bed Occupancy Rate', 'Population', 'Population (20+)', 'Population (65+)',\n",
        "    'Staffed_Beds_Population', 'Licensed_Beds_Population', 'Staffed_Beds_Squared', 'Population_Squared'\n",
        "]\n",
        "numerical_cols = [col for col in numerical_cols if col in X_train.columns]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "# 6. Imputation (for Linear Regression)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# 7. Model Training\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_imputed, y_train)\n",
        "    print(f\"{name} trained successfully.\")\n",
        "\n",
        "# 8. Evaluation\n",
        "epsilon = 1e-10\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test_imputed)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
        "\n",
        "    print(f\"\\n{name} Evaluation Metrics:\")\n",
        "    print(f\"  MAE  : {mae:.3f}\")\n",
        "    print(f\"  RMSE : {rmse:.3f}\")\n",
        "    print(f\"  R²   : {r2:.3f}\")\n",
        "    print(f\"  MAPE : {mape:.3f}%\")\n"
      ]
    }
  ]
}